{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5e3ef2d",
   "metadata": {},
   "source": [
    "# 1. Import Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd2d5ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b264c43",
   "metadata": {},
   "source": [
    "\n",
    "# 2. Data Loading\n",
    "### 2.1 Define File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f488a291",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUSINESS_PLANNING = os.path.join('data', 'CensusBusinessPlanning')\n",
    "business_files = os.listdir(BUSINESS_PLANNING)\n",
    "\n",
    "QUARTERLY_EMPLOYMENT = os.path.join('data', 'QuarterlyCensusEmployment')\n",
    "quarterly_employment_files = os.listdir(QUARTERLY_EMPLOYMENT)\n",
    "\n",
    "YEARLY_EMPLOYMENT = os.path.join('data', 'YearlyCensusEmployment')\n",
    "yearly_employmet_files = os.listdir(YEARLY_EMPLOYMENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66c8844",
   "metadata": {},
   "source": [
    "### 2.2 Build Data Loading Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e3fd473f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_files(path, dir_list):\n",
    "    data_frames = {}\n",
    "    \n",
    "    for file in dir_list:\n",
    "        var = file.split(\".\")[0]\n",
    "        file_path = os.path.join(path, file)\n",
    "        \n",
    "        if '.csv' in file:\n",
    "            data_frames[var] = pd.read_csv(file_path, dtype=str, low_memory=False)\n",
    "        elif '.xlsx' in file:\n",
    "            print(\"Loading and converting file:\", file)\n",
    "            \n",
    "            # Convert Excel to CSV\n",
    "            df = pd.read_excel(file_path, sheet_name=0, engine='calamine')\n",
    "            \n",
    "            # Create CSV file path\n",
    "            csv_file_path = os.path.join(path, f\"{var}.csv\")\n",
    "            df.to_csv(csv_file_path, index=False)\n",
    "            \n",
    "            print(f\"Converted {file} to CSV: {var}.csv\")\n",
    "            \n",
    "            # Store the dataframe\n",
    "            data_frames[var] = df\n",
    "    \n",
    "    return data_frames\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b481013",
   "metadata": {},
   "source": [
    "### 2.3 Load in Files as Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "058c2314",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbp_dict = load_files(BUSINESS_PLANNING, business_files)\n",
    "\n",
    "q_emp_dict = load_files(QUARTERLY_EMPLOYMENT, quarterly_employment_files)\n",
    "\n",
    "y_emp_dict = load_files(YEARLY_EMPLOYMENT, yearly_employmet_files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4b7c1c",
   "metadata": {},
   "source": [
    "### 2.4 Load in Other Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4d9be11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "county_gdp = pd.read_csv('data/CountyGDP.csv', dtype=str, low_memory=False, encoding='latin-1')\n",
    "\n",
    "county_income = pd.read_csv(\"data/CountyIncome.csv\", dtype = str, low_memory = False, encoding='latin-1' )\n",
    "\n",
    "construction_permits = pd.read_csv(\"Data/ResidentialConstructionPermitsCounty.csv\", dtype=str, low_memory = False, encoding='latin-1') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22371f15",
   "metadata": {},
   "source": [
    "# 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9c7ed3",
   "metadata": {},
   "source": [
    "### 3.1 Census Business Planning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "96329e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 0 already removed\n"
     ]
    }
   ],
   "source": [
    "def standardize_cbp_columns(cbp_dict):\n",
    "    \"\"\"Remove unnecessary columns and standardize based on year\"\"\"\n",
    "    for df in cbp_dict.keys():\n",
    "        year = df[0:4]\n",
    "        if int(year) < 2017:\n",
    "            use = \"2012\"\n",
    "        else:\n",
    "            use = \"2017\"\n",
    "        keep = ['GEO_ID', 'YEAR', 'NAME', f'NAICS{use}', f'NAICS{use}_LABEL',  \n",
    "                'EMPSZES_LABEL', 'ESTAB', 'EMP', 'PAYANN']\n",
    "        cbp_dict[df] = cbp_dict[df][keep]\n",
    "    return cbp_dict\n",
    "\n",
    "def remove_first_row(cbp_dict):\n",
    "    \"\"\"Remove first row from CBP\"\"\"\n",
    "    try:\n",
    "        for df in cbp_dict.keys():\n",
    "            cbp_dict[df] = cbp_dict[df].drop(0)\n",
    "    except:\n",
    "        print(\"Row 0 already removed\")\n",
    "    return cbp_dict\n",
    "\n",
    "def combine_dfs(dict):\n",
    "    standardized_df = []\n",
    "    for key, value in dict.items():\n",
    "        df_copy = value.copy()\n",
    "        df_copy = df_copy.rename(columns={\n",
    "            \"NAICS2012\" : \"NAICS\", \n",
    "            \"NAICS2017\" : \"NAICS\", \n",
    "            \"NAICS2012_LABEL\" : \"NAICS_LABEL\", \n",
    "            \"NAICS2017_LABEL\" : \"NAICS_LABEL\"\n",
    "        })\n",
    "\n",
    "        standardized_df.append(df_copy)\n",
    "    combined_df = pd.concat(standardized_df, ignore_index=True)\n",
    "    return combined_df\n",
    "\n",
    "cbp_dict = remove_first_row(cbp_dict)\n",
    "cbp_dict = standardize_cbp_columns(cbp_dict)\n",
    "cbp_df = combine_dfs(cbp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6d46c531",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_abbrev = {\n",
    "    'Alabama': 'AL', 'Alaska': 'AK', 'Arizona': 'AZ', 'Arkansas': 'AR',\n",
    "    'California': 'CA', 'Colorado': 'CO', 'Connecticut': 'CT', 'Delaware': 'DE',\n",
    "    'Florida': 'FL', 'Georgia': 'GA', 'Hawaii': 'HI', 'Idaho': 'ID',\n",
    "    'Illinois': 'IL', 'Indiana': 'IN', 'Iowa': 'IA', 'Kansas': 'KS',\n",
    "    'Kentucky': 'KY', 'Louisiana': 'LA', 'Maine': 'ME', 'Maryland': 'MD',\n",
    "    'Massachusetts': 'MA', 'Michigan': 'MI', 'Minnesota': 'MN', 'Mississippi': 'MS',\n",
    "    'Missouri': 'MO', 'Montana': 'MT', 'Nebraska': 'NE', 'Nevada': 'NV',\n",
    "    'New Hampshire': 'NH', 'New Jersey': 'NJ', 'New Mexico': 'NM', 'New York': 'NY',\n",
    "    'North Carolina': 'NC', 'North Dakota': 'ND', 'Ohio': 'OH', 'Oklahoma': 'OK',\n",
    "    'Oregon': 'OR', 'Pennsylvania': 'PA', 'Rhode Island': 'RI', 'South Carolina': 'SC',\n",
    "    'South Dakota': 'SD', 'Tennessee': 'TN', 'Texas': 'TX', 'Utah': 'UT',\n",
    "    'Vermont': 'VT', 'Virginia': 'VA', 'Washington': 'WA', 'West Virginia': 'WV',\n",
    "    'Wisconsin': 'WI', 'Wyoming': 'WY', 'District of Columbia': 'DC'\n",
    "}\n",
    "\n",
    "def filter_cbp(df):\n",
    "    temp = df[df['EMPSZES_LABEL'] == \"All establishments\"]\n",
    "    temp = temp[temp['NAICS_LABEL'].isin(['Total for all sectors', 'Retail trade', 'Accommodation and food services'])]\n",
    "    return temp\n",
    "\n",
    "\n",
    "# Filter for specific industries\n",
    "cbp_df = filter_cbp(cbp_df)\n",
    "\n",
    "# Seperate County and State from NAME\n",
    "cbp_df[['County', 'State']] = cbp_df['NAME'].str.split(\",\", expand=True)\n",
    "cbp_df['State'] = cbp_df['State'].str.strip().map(state_abbrev)\n",
    "cbp_df = cbp_df.dropna(subset=['State'])\n",
    "cbp_df = cbp_df.reset_index(drop=True)\n",
    "cbp_df['County'] = cbp_df['County'].str.split().str[:-1].str.join(' ').str.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dad8e0",
   "metadata": {},
   "source": [
    "## 3.2 Quarterly Employment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "73d425f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_quarterly_employment_data(q_emp_dict, state_abbrev):\n",
    "   \"\"\"\n",
    "   Process all employment dataframes in dictionary and combine into one.\n",
    "   \n",
    "   Parameters:\n",
    "   q_emp_dict: Dictionary with dataframe names as keys and dataframes as values\n",
    "   state_abbrev: Dictionary mapping state names to abbreviations\n",
    "   \n",
    "   Returns:\n",
    "   Combined processed dataframe\n",
    "   \"\"\"\n",
    "   processed_dfs = []\n",
    "   \n",
    "   for key, df in q_emp_dict.items():\n",
    "       temp = df.copy()\n",
    "       temp = temp.dropna(subset=['St Name'])\n",
    "       \n",
    "       \n",
    "       numeric_cols = temp.iloc[:, 14:17].apply(pd.to_numeric, errors='coerce')\n",
    "       temp.loc[:, 'average_employment'] = numeric_cols.mean(axis=1)\n",
    "       \n",
    "       # Drop original columns and filter for counties\n",
    "       temp = temp.drop(columns=temp.columns[14:17]) \n",
    "       temp = temp[temp[\"Area Type\"] == \"County\"]\n",
    "       \n",
    "       # Split area into county and state\n",
    "       temp[['County', 'State']] = temp['Area'].str.split(\",\", expand=True)\n",
    "       temp['State'] = temp['State'].str.strip().map(state_abbrev)\n",
    "       \n",
    "       # Select and reorder columns\n",
    "       temp = temp[['Year', 'Qtr','County', 'State','NAICS', \n",
    "                  'Area Type', 'Ownership', 'Industry', 'Status Code',\n",
    "                  'Establishment Count', 'Total Quarterly Wages', 'Average Weekly Wage',\n",
    "                  'Employment Location Quotient Relative to U.S.',\n",
    "                  'Total Wage Location Quotient Relative to U.S.', 'average_employment']]\n",
    "       \n",
    "       processed_dfs.append(temp)\n",
    "   \n",
    "   # Combine all processed dataframes\n",
    "   combined_df = pd.concat(processed_dfs, ignore_index=True)\n",
    "   \n",
    "   return combined_df\n",
    "\n",
    "\n",
    "quarterly_employment_df = process_quarterly_employment_data(q_emp_dict, state_abbrev)\n",
    "quarterly_employment_df['County'] = quarterly_employment_df['County'].str.split().str[:-1].str.join(' ').str.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77382ae4",
   "metadata": {},
   "source": [
    "## 3.3 Yearly Employment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "360b715b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_yearly_employment_data(y_emp_dict, state_abbrev):\n",
    "   \"\"\"\n",
    "   Process all employment dataframes in dictionary and combine into one.\n",
    "   \n",
    "   Parameters:\n",
    "   q_emp_dict: Dictionary with dataframe names as keys and dataframes as values\n",
    "   state_abbrev: Dictionary mapping state names to abbreviations\n",
    "   \n",
    "   Returns:\n",
    "   Combined processed dataframe\n",
    "   \"\"\"\n",
    "   processed_dfs = []\n",
    "   \n",
    "   for key, df in y_emp_dict.items():\n",
    "       temp = df.copy()\n",
    "       temp = temp[temp[\"Area Type\"] == \"County\"]\n",
    "       \n",
    "       # Split area into county and state\n",
    "       temp[['County', 'State']] = temp['Area'].str.split(\",\", expand=True)\n",
    "       temp['State'] = temp['State'].str.strip().map(state_abbrev)\n",
    "       \n",
    "       processed_dfs.append(temp)\n",
    "   \n",
    "   \n",
    "   combined_df = pd.concat(processed_dfs, ignore_index=True)\n",
    "   combined_df = combined_df[[ 'Year', 'Qtr', 'County', 'State','NAICS',\n",
    "       'Area Type', 'Ownership', 'Industry',\n",
    "       'Annual Average Status Code', 'Annual Average Establishment Count',\n",
    "       'Annual Average Employment', 'Annual Total Wages',\n",
    "       'Annual Average Weekly Wage', 'Annual Average Pay',\n",
    "       'Employment Location Quotient Relative to U.S.',\n",
    "       'Total Wage Location Quotient Relative to U.S.', ]]\n",
    "   \n",
    "   \n",
    "   return combined_df\n",
    "\n",
    "yearly_employment_df = process_yearly_employment_data(y_emp_dict, state_abbrev)\n",
    "yearly_employment_df['County'] = yearly_employment_df['County'].str.split().str[:-1].str.join(' ').str.upper()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980362c2",
   "metadata": {},
   "source": [
    "## 3.4 County Income and GDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d4d98060",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_county(county_df):\n",
    "   \"\"\"\n",
    "   Process county dataframes by splitting GeoName into County and State,\n",
    "   cleaning the data, and reordering columns.\n",
    "   \n",
    "   Parameters:\n",
    "   df_df: DataFrame with county income data\n",
    "   \n",
    "   Returns:\n",
    "   Processed DataFrame with cleaned County and State columns\n",
    "   \"\"\"\n",
    "   df = county_df[['GeoFIPS', 'GeoName', 'TableName',\n",
    "                                    'IndustryClassification', 'Description', 'Unit', '2014', '2015', '2016',\n",
    "                                    '2017', '2018', '2019', '2020', '2021', '2022', '2023']].copy()\n",
    "   \n",
    "   # Filter to only rows that contain a comma\n",
    "   df = df[df['GeoName'].str.contains(',', na=False)]\n",
    "   \n",
    "   # Split GeoName into County and State\n",
    "   df[['County', 'State']] = df['GeoName'].str.split(\",\", n=1, expand=True)\n",
    "   \n",
    "   # Clean County and State columns\n",
    "   df['County'] = df['County'].str.strip()\n",
    "   df['State'] = df['State'].str.strip().str.replace('*', '', regex=False)\n",
    "   df['County'] = df['County'] + \" County\"\n",
    "   \n",
    "   df = df[['GeoFIPS', 'GeoName', 'County', 'State',\n",
    "                                 'Description', 'Unit', '2014', '2015', '2016',\n",
    "                                 '2017', '2018', '2019', '2020', '2021', '2022', '2023']]\n",
    "   \n",
    "   return df\n",
    "\n",
    "processed_income = process_county(county_income)\n",
    "processed_income['County'] = processed_income['County'].str.split().str[:-1].str.join(' ').str.upper()\n",
    "processed_gdp = process_county(county_gdp)\n",
    "processed_gdp['County'] = processed_gdp['County'].str.split().str[:-1].str.join(' ').str.upper()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd41a5dd",
   "metadata": {},
   "source": [
    "## 3.5 Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55db40e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>County</th>\n",
       "      <th>State</th>\n",
       "      <th>year</th>\n",
       "      <th>permits_5plus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AUTAUGA</td>\n",
       "      <td>AL</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AUTAUGA</td>\n",
       "      <td>AL</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AUTAUGA</td>\n",
       "      <td>AL</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AUTAUGA</td>\n",
       "      <td>AL</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AUTAUGA</td>\n",
       "      <td>AL</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28984</th>\n",
       "      <td>WESTON</td>\n",
       "      <td>WY</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28985</th>\n",
       "      <td>WESTON</td>\n",
       "      <td>WY</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28986</th>\n",
       "      <td>WESTON</td>\n",
       "      <td>WY</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28987</th>\n",
       "      <td>WESTON</td>\n",
       "      <td>WY</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28988</th>\n",
       "      <td>WESTON</td>\n",
       "      <td>WY</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28989 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        County State  year  permits_5plus\n",
       "0      AUTAUGA    AL  2014            0.0\n",
       "1      AUTAUGA    AL  2015            0.0\n",
       "2      AUTAUGA    AL  2016            0.0\n",
       "3      AUTAUGA    AL  2017            0.0\n",
       "4      AUTAUGA    AL  2018            0.0\n",
       "...        ...   ...   ...            ...\n",
       "28984   WESTON    WY  2018            0.0\n",
       "28985   WESTON    WY  2019            0.0\n",
       "28986   WESTON    WY  2020            0.0\n",
       "28987   WESTON    WY  2021            0.0\n",
       "28988   WESTON    WY  2022            0.0\n",
       "\n",
       "[28989 rows x 4 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def prepare_permits(df, start_year=2014, end_year=2022):\n",
    "    \"\"\"\n",
    "    Prepare permits data specifically for residential development impact forecasting\n",
    "    \n",
    "    Parameters:\n",
    "    df: DataFrame with building permits data\n",
    "    start_year: Starting year for analysis (default: 2014)\n",
    "    end_year: Ending year for analysis (default: 2022)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Base identification columns\n",
    "    base_cols = ['GEOID', 'STATE', 'COUNTY', 'NAME', 'STATE_NAME']\n",
    "    \n",
    "    # Validate required columns exist\n",
    "    missing_cols = [col for col in base_cols if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "    \n",
    "    surge_cols = []\n",
    "   \n",
    "    for year in range(start_year, end_year + 1):\n",
    "        if year == 2022:\n",
    "            # Special case for 2022 with different column name\n",
    "            col_name = f'MULTIFAMILY_PERMITS_5_OR_MORE_{year}'\n",
    "        else:\n",
    "            col_name = f'MULTIFAMILY_PERMITS_5_OR_MORE_UNITS_{year}'\n",
    "        \n",
    "        if col_name in df.columns:\n",
    "            surge_cols.append(col_name)\n",
    "        else:\n",
    "            print(f\"Warning: Column {col_name} not found in dataset\")\n",
    "    \n",
    "    if not surge_cols:\n",
    "        raise ValueError(f\"No 5+ unit permit columns found for years {start_year}-{end_year}\")\n",
    "        \n",
    "    project_df = df[base_cols + surge_cols].copy()\n",
    "    \n",
    "    # Reshape to long format for time series analysis\n",
    "    project_long = project_df.melt(\n",
    "        id_vars=base_cols,\n",
    "        value_vars=surge_cols,\n",
    "        var_name='year_col',\n",
    "        value_name='permits_5plus'\n",
    "    )\n",
    "    \n",
    "    project_long['year'] = project_long['year_col'].str.extract(r'(\\d{4})').astype(int)\n",
    "    project_long = project_long.drop('year_col', axis=1)\n",
    "    \n",
    "    # Handle missing values and ensure proper data types\n",
    "    project_long['permits_5plus'] = pd.to_numeric(project_long['permits_5plus'], errors='coerce').fillna(0)\n",
    "    \n",
    "    # Sort by location and year for better organization\n",
    "    project_long = project_long.sort_values(['STATE_NAME', 'NAME', 'year']).reset_index(drop=True)\n",
    "    return project_long\n",
    "\n",
    "def fix_permits(df, state_abbrev):\n",
    "    df = df[['NAME','STATE_NAME', 'year', 'permits_5plus']].copy()\n",
    "    df['NAME'] = df['NAME'].str.upper()\n",
    "    df['STATE_NAME'] = df['STATE_NAME'].str.strip().map(state_abbrev)\n",
    "\n",
    "    df = df.rename(columns={\n",
    "    \"NAME\" : \"County\", \n",
    "    \"STATE_NAME\" : \"State\"\n",
    "    })\n",
    "    return df\n",
    "\n",
    "const_permits = prepare_permits(construction_permits)\n",
    "const_permits = fix_permits(const_permits, state_abbrev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2459a531",
   "metadata": {},
   "source": [
    "# 4. Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105fdac1",
   "metadata": {},
   "source": [
    "## 4.1 Census Business Planning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "25d7e925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types after conversion:\n",
      "YEAR        int64\n",
      "ESTAB     float64\n",
      "EMP       float64\n",
      "PAYANN    float64\n",
      "dtype: object\n",
      "\n",
      "Any missing values created?\n",
      "YEAR        0\n",
      "ESTAB       1\n",
      "EMP       652\n",
      "PAYANN    433\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Convert string columns to numeric\n",
    "numeric_cols = ['YEAR', 'ESTAB', 'EMP', 'PAYANN']\n",
    "\n",
    "for col in numeric_cols:\n",
    "    cbp_df[col] = pd.to_numeric(cbp_df[col], errors='coerce')\n",
    "\n",
    "    # Check the conversion worked\n",
    "print(\"Data types after conversion:\")\n",
    "print(cbp_df[numeric_cols].dtypes)\n",
    "print(\"\\nAny missing values created?\")\n",
    "print(cbp_df[numeric_cols].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9199e48",
   "metadata": {},
   "source": [
    "#### Functions to create visuals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dd3a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "def get_sector_summary(results):\n",
    "    summary_data = []\n",
    "    sector_mapping = {\n",
    "        'all_sectors': 'All Sectors',\n",
    "        'retail_trade': 'Retail Trade',\n",
    "        'accommodation_food': 'Accommodation & Food Services'\n",
    "    }\n",
    "    \n",
    "    for key, sector_name in sector_mapping.items():\n",
    "        if results[key] is not None and not results[key].empty:\n",
    "            data = results[key]\n",
    "            summary_data.append({\n",
    "                'Sector': sector_name,\n",
    "                'Counties_Analyzed': len(data),\n",
    "                'Max_Employment': data['EMP'].max(),\n",
    "                'Min_Employment': data['EMP'].min(),\n",
    "                'Avg_Employment': data['EMP'].mean(),\n",
    "                'Top_County': f\"{data.iloc[0]['County']}, {data.iloc[0]['State']}\"\n",
    "            })\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    return summary_df\n",
    "\n",
    "def plot_top_counties(results, sector='all_sectors', top_n=10):  \n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    if results[sector] is None or results[sector].empty:\n",
    "        print(f\"No data available for sector: {sector}\")\n",
    "        return\n",
    "    \n",
    "    data = results[sector].head(top_n)\n",
    "    \n",
    "    # Create labels with county and state\n",
    "    labels = [f\"{row['County']}, {row['State']}\" for _, row in data.iterrows()]\n",
    "    \n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    bars = plt.barh(range(len(data)), data['EMP'], color='steelblue', alpha=0.7)\n",
    "    \n",
    "    # Customize the plot\n",
    "    plt.yticks(range(len(data)), labels)\n",
    "    plt.xlabel('Average Employment')\n",
    "    plt.title(f'Top {top_n} Counties by Average Employment - {sector.replace(\"_\", \" \").title()}')\n",
    "    plt.gca().invert_yaxis()  # Highest values at the top\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, (bar, value) in enumerate(zip(bars, data['EMP'])):\n",
    "        plt.text(bar.get_width() + max(data['EMP']) * 0.01, \n",
    "                bar.get_y() + bar.get_height()/2, \n",
    "                f'{value:,.0f}', \n",
    "                ha='left', va='center', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def get_employment_summary_stats(cbp_df, sectors=['Total for all sectors', 'Retail trade', 'Accommodation and food services']):\n",
    "    \"\"\"\n",
    "    Get summary statistics for employment distributions across different sectors using ALL data.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Group data (same as in analyze_county_employment but use ALL data)\n",
    "    cbp_group_county = cbp_df.groupby(['County', 'State', 'NAICS_LABEL'])['EMP'].mean().reset_index()\n",
    "    \n",
    "    summary_data = []\n",
    "    \n",
    "    for sector in sectors:\n",
    "        sector_data = cbp_group_county[cbp_group_county['NAICS_LABEL'] == sector]\n",
    "        \n",
    "        if not sector_data.empty:\n",
    "            # Remove any NaN or infinite values\n",
    "            clean_data = sector_data['EMP'].dropna()\n",
    "            clean_data = clean_data[clean_data != float('inf')]\n",
    "            clean_data = clean_data[clean_data != float('-inf')]\n",
    "            \n",
    "            if len(clean_data) > 0:\n",
    "                summary_data.append({\n",
    "                    'Sector': sector,\n",
    "                    'Count': len(clean_data),\n",
    "                    'Mean': clean_data.mean(),\n",
    "                    'Median': clean_data.median(),\n",
    "                    'Std': clean_data.std(),\n",
    "                    'Min': clean_data.min(),\n",
    "                    'Max': clean_data.max(),\n",
    "                    'Q1': clean_data.quantile(0.25),\n",
    "                    'Q3': clean_data.quantile(0.75)\n",
    "                })\n",
    "            else:\n",
    "                print(f\"No valid data for sector: {sector}\")\n",
    "        else:\n",
    "            print(f\"No data found for sector: {sector}\")\n",
    "    \n",
    "    if summary_data:\n",
    "        return pd.DataFrame(summary_data)\n",
    "    else:\n",
    "        print(\"No data available for any of the specified sectors\")\n",
    "        return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69472aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_down_counties(df, top_n=500):\n",
    "    # Group by county with average employment since 2014\n",
    "    df_group_county = df.groupby(['County', 'State', 'NAICS_LABEL'])['EMP'].mean().reset_index()\n",
    "\n",
    "    # Filter to all sectors and keep top n\n",
    "    all_sectors = df_group_county[df_group_county['NAICS_LABEL'] == \"Total for all sectors\"]\n",
    "    all_sectors = all_sectors.nlargest(top_n, 'EMP')\n",
    "\n",
    "    # Get list of top n counties\n",
    "    counties = all_sectors['County'].to_list()\n",
    "    states = all_sectors['State'].to_list()\n",
    "\n",
    "    top_county_state = set(zip(counties, states))\n",
    "\n",
    "    # Filter Retail Trade\n",
    "    retail_trade = df_group_county[\n",
    "        (df_group_county['NAICS_LABEL'] == \"Retail trade\") &\n",
    "        (df_group_county.apply(lambda row: (row['County'], row['State']) in top_county_state, axis=1))\n",
    "    ].sort_values(\"EMP\", ascending=False)\n",
    "\n",
    "    # Filter Accommodation and Food Services\n",
    "    accommodation_food = df_group_county[\n",
    "        (df_group_county['NAICS_LABEL'] == \"Accommodation and food services\") &\n",
    "        (df_group_county.apply(lambda row: (row['County'], row['State']) in top_county_state, axis=1))\n",
    "    ].sort_values(\"EMP\", ascending=False)\n",
    "\n",
    "    print(\"Retail Trade sample:\")\n",
    "    print(retail_trade.head())\n",
    "\n",
    "    print(\"Accommodation and Food Services sample:\")\n",
    "    print(accommodation_food.head())\n",
    "\n",
    "    results = {\n",
    "        'grouped_data': df_group_county,\n",
    "        'all_sectors': all_sectors,\n",
    "        'retail_trade': retail_trade,\n",
    "        'accommodation_food': accommodation_food\n",
    "    }\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e206383a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = filter_down_counties(cbp_df, top_n=500)\n",
    "\n",
    "# Get summary statistics\n",
    "summary = get_sector_summary(results)\n",
    "print(\"\\nEmployment Analysis Summary\")\n",
    "print(\"=\" * 30)\n",
    "display(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7364225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results - these use the top N from results\n",
    "plot_top_counties(results, sector='all_sectors', top_n=10)\n",
    "plot_top_counties(results, sector='retail_trade', top_n=10)\n",
    "plot_top_counties(results, sector='accommodation_food', top_n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "413c232c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Full Employment Statistics (All Counties)\n",
      "========================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sector</th>\n",
       "      <th>Count</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>Std</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Total for all sectors</td>\n",
       "      <td>3148</td>\n",
       "      <td>39623.299975</td>\n",
       "      <td>6579.65</td>\n",
       "      <td>145142.824679</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>3883290.7</td>\n",
       "      <td>2143.425000</td>\n",
       "      <td>20917.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Retail trade</td>\n",
       "      <td>3138</td>\n",
       "      <td>5035.436825</td>\n",
       "      <td>1013.55</td>\n",
       "      <td>15433.634038</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>416644.2</td>\n",
       "      <td>323.175000</td>\n",
       "      <td>3255.425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Accommodation and food services</td>\n",
       "      <td>3112</td>\n",
       "      <td>4429.377898</td>\n",
       "      <td>741.15</td>\n",
       "      <td>16083.290330</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>436935.9</td>\n",
       "      <td>214.361111</td>\n",
       "      <td>2597.175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Sector  Count          Mean   Median  \\\n",
       "0            Total for all sectors   3148  39623.299975  6579.65   \n",
       "1                     Retail trade   3138   5035.436825  1013.55   \n",
       "2  Accommodation and food services   3112   4429.377898   741.15   \n",
       "\n",
       "             Std        Min        Max           Q1         Q3  \n",
       "0  145142.824679  21.000000  3883290.7  2143.425000  20917.050  \n",
       "1   15433.634038   5.666667   416644.2   323.175000   3255.425  \n",
       "2   16083.290330   1.000000   436935.9   214.361111   2597.175  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get summary statistics for ALL counties in each sector\n",
    "full_stats = get_employment_summary_stats(cbp_df)\n",
    "print(\"\\nFull Employment Statistics (All Counties)\")\n",
    "print(\"=\" * 40)\n",
    "display(full_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6f4e7d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Generate lists to focus on for analysis\n",
    "\n",
    "reducedCounties = results['all_sectors']['County'].tolist()\n",
    "reducedStates = results['all_sectors']['State'].tolist()\n",
    "reducedFull = list(zip(reducedCounties, reducedStates))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b670653f",
   "metadata": {},
   "source": [
    "## 4.2 Quarterly Employment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "b25a2bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_employment(df, reducedFull):\n",
    "    df = df.copy()\n",
    "    filter_index = pd.MultiIndex.from_tuples(reducedFull, names=['County', 'State'])\n",
    "    filtered_df = df[df.set_index(['County', 'State']).index.isin(filter_index)].reset_index(drop=True)\n",
    "    return filtered_df\n",
    "\n",
    "\n",
    "quarterly_employment_df = filter_employment(quarterly_employment_df, reducedFull)\n",
    "yearly_employment_df = filter_employment(yearly_employment_df, reducedFull)\n",
    "processed_income = filter_employment(processed_income, reducedFull)\n",
    "processed_gdp = filter_employment(processed_gdp, reducedFull)\n",
    "const_permits = filter_employment(const_permits, reducedFull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "9a21ddb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quarterly Employment:\n",
      "  CBP only: 20 counties\n",
      "  quarterly employment only: 0 counties\n",
      "  CBP examples: [('NORFOLK', 'VA'), ('LYNCHBURG', 'VA'), ('FAIRFAX', 'VA')]\n",
      "\n",
      "Yearly Employment:\n",
      "  CBP only: 20 counties\n",
      "  yearly employment only: 0 counties\n",
      "  CBP examples: [('NORFOLK', 'VA'), ('LYNCHBURG', 'VA'), ('FAIRFAX', 'VA')]\n",
      "\n",
      "Processed Income:\n",
      "  CBP only: 20 counties\n",
      "  processed income only: 0 counties\n",
      "  CBP examples: [('NORFOLK', 'VA'), ('LYNCHBURG', 'VA'), ('FAIRFAX', 'VA')]\n",
      "\n",
      "Processed Gdp:\n",
      "  CBP only: 20 counties\n",
      "  processed gdp only: 0 counties\n",
      "  CBP examples: [('NORFOLK', 'VA'), ('LYNCHBURG', 'VA'), ('FAIRFAX', 'VA')]\n",
      "\n",
      "Construction Permits:\n",
      "  CBP only: 9 counties\n",
      "  construction permits only: 0 counties\n",
      "  CBP examples: [('CAPITOL PLANNING', 'CT'), ('WESTERN CONNECTICUT PLANNING', 'CT'), ('DISTRICT OF', 'DC')]\n"
     ]
    }
   ],
   "source": [
    "# Create (county, state) tuple sets for comparison\n",
    "reducedFull_tuples = set(reducedFull)\n",
    "\n",
    "datasets = {\n",
    "    'quarterly employment': set(zip(quarterly_employment_df['County'], quarterly_employment_df['State'])),\n",
    "    'yearly employment': set(zip(yearly_employment_df['County'], yearly_employment_df['State'])),\n",
    "    'processed income': set(zip(processed_income['County'], processed_income['State'])),\n",
    "    'processed gdp': set(zip(processed_gdp['County'], processed_gdp['State'])), \n",
    "    'construction permits': set(zip(const_permits['County'], const_permits['State']))\n",
    "}\n",
    "\n",
    "# Compare CBP with each dataset\n",
    "for name, dataset_tuples in datasets.items():\n",
    "    cbp_only = reducedFull_tuples - dataset_tuples\n",
    "    dataset_only = dataset_tuples - reducedFull_tuples\n",
    "    \n",
    "    print(f\"\\n{name.title()}:\")\n",
    "    print(f\"  CBP only: {len(cbp_only)} counties\")\n",
    "    print(f\"  {name} only: {len(dataset_only)} counties\")\n",
    "    \n",
    "    if cbp_only:\n",
    "        print(f\"  CBP examples: {list(cbp_only)[:3]}\")\n",
    "    if dataset_only:\n",
    "        print(f\"  {name} examples: {list(dataset_only)[:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "7a5f2a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of counties common to all datasets: 480\n",
      "Common counties (first 10): [('OLMSTED', 'MN'), ('GRAND TRAVERSE', 'MI'), ('WINNEBAGO', 'IL'), ('POLK', 'FL'), ('ORANGE', 'NC'), ('OKALOOSA', 'FL'), ('CHESTERFIELD', 'VA'), ('CLARK', 'NV'), ('SARASOTA', 'FL'), ('ESSEX', 'MA')]\n"
     ]
    }
   ],
   "source": [
    "# Create (county, state) tuple sets for all datasets\n",
    "reducedFull_tuples = set(reducedFull)\n",
    "quarterly_tuples = set(zip(quarterly_employment_df['County'], quarterly_employment_df['State']))\n",
    "yearly_tuples = set(zip(yearly_employment_df['County'], yearly_employment_df['State']))\n",
    "income_tuples = set(zip(processed_income['County'], processed_income['State']))\n",
    "gdp_tuples = set(zip(processed_gdp['County'], processed_gdp['State']))\n",
    "const_tuples = set(zip(const_permits['County'], const_permits['State']))\n",
    "\n",
    "# Find intersection of all county-state tuple sets\n",
    "common_county_state_tuples = reducedFull_tuples.intersection(\n",
    "    quarterly_tuples,\n",
    "    yearly_tuples,\n",
    "    income_tuples,\n",
    "    gdp_tuples, \n",
    "    const_tuples\n",
    ")\n",
    "\n",
    "# Convert back to list if needed\n",
    "common_county_state_tuples = list(common_county_state_tuples)\n",
    "\n",
    "print(f\"Number of counties common to all datasets: {len(common_county_state_tuples)}\")\n",
    "print(f\"Common counties (first 10): {common_county_state_tuples[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "2d849fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More filtering based on common counties\n",
    "quarterly_employment_df = filter_employment(quarterly_employment_df, common_county_state_tuples)\n",
    "yearly_employment_df = filter_employment(yearly_employment_df, common_county_state_tuples)\n",
    "processed_income = filter_employment(processed_income, common_county_state_tuples)\n",
    "processed_gdp = filter_employment(processed_gdp, common_county_state_tuples)\n",
    "const_permits = filter_employment(const_permits, common_county_state_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "66d87062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'TX': 32,\n",
       "         'CA': 31,\n",
       "         'FL': 28,\n",
       "         'PA': 28,\n",
       "         'NY': 24,\n",
       "         'OH': 21,\n",
       "         'NC': 18,\n",
       "         'NJ': 17,\n",
       "         'MI': 16,\n",
       "         'GA': 16,\n",
       "         'IL': 15,\n",
       "         'WI': 14,\n",
       "         'IN': 14,\n",
       "         'TN': 13,\n",
       "         'CO': 12,\n",
       "         'SC': 12,\n",
       "         'MA': 11,\n",
       "         'WA': 10,\n",
       "         'AL': 10,\n",
       "         'LA': 10,\n",
       "         'MN': 9,\n",
       "         'MD': 9,\n",
       "         'MO': 8,\n",
       "         'IA': 7,\n",
       "         'OR': 7,\n",
       "         'AZ': 7,\n",
       "         'MS': 7,\n",
       "         'VA': 6,\n",
       "         'UT': 6,\n",
       "         'CT': 6,\n",
       "         'ME': 5,\n",
       "         'KY': 5,\n",
       "         'AR': 5,\n",
       "         'KS': 4,\n",
       "         'NH': 4,\n",
       "         'ID': 4,\n",
       "         'WV': 3,\n",
       "         'DE': 3,\n",
       "         'RI': 3,\n",
       "         'OK': 3,\n",
       "         'MT': 3,\n",
       "         'NE': 3,\n",
       "         'NV': 2,\n",
       "         'HI': 2,\n",
       "         'SD': 2,\n",
       "         'NM': 2,\n",
       "         'ND': 2,\n",
       "         'VT': 1})"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "states = [state for (county, state) in common_county_state_tuples]\n",
    "counts = Counter(states)\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9b5bc6",
   "metadata": {},
   "source": [
    "# FIPS Code Merging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430fd8db",
   "metadata": {},
   "source": [
    "# Development Surge Indicator Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9b8d92",
   "metadata": {},
   "source": [
    "# Quarterly Frequency Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358f0270",
   "metadata": {},
   "source": [
    "# Feature Engineering (PDFM + Economic Variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1839f6a5",
   "metadata": {},
   "source": [
    "# Train/Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9554db08",
   "metadata": {},
   "source": [
    "# TimesFM Model Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d647d8cb",
   "metadata": {},
   "source": [
    "# Baseline Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e55951",
   "metadata": {},
   "source": [
    "# Treatment Effect Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ddf871",
   "metadata": {},
   "source": [
    "# Model Validation & Backtesting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d25b5b1",
   "metadata": {},
   "source": [
    "# Insights & Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e369d0ea",
   "metadata": {},
   "source": [
    "# Dashboard Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f87751d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
